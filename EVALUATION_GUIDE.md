# Guide d'√âvaluation - √âtape 5 du TP

Ce guide explique comment utiliser le script `evaluate.py` pour √©valuer votre mod√®le U-Net sur le test set de MUSDB et calculer les m√©triques standard (SDR, SIR, SAR).

## üìã Pr√©requis

### 1. Installation des d√©pendances

Assurez-vous d'avoir install√© toutes les d√©pendances :

```bash
pip install -r requirements.txt
```

Les nouvelles d√©pendances n√©cessaires pour l'√©valuation sont :
- `museval>=0.4.0` : Biblioth√®que d'√©valuation des m√©triques de s√©paration de sources
- `pandas>=1.3.0` : Pour le traitement des r√©sultats

### 2. Mod√®le entra√Æn√©

Vous devez avoir un mod√®le entra√Æn√© sauvegard√© dans :
- `vocal_checkpoints/best_model.pth` (recommand√©)
- ou `checkpoints/best_model.pth`

### 3. Dataset MUSDB

Le dataset MUSDB doit √™tre disponible dans :
- `MUSDB18/musdb18/` (chemin relatif)
- ou sp√©cifiez le chemin avec `--musdb-path`

## üöÄ Utilisation

### Utilisation de base

```bash
python evaluate.py
```

Le script va automatiquement :
1. Chercher le checkpoint dans `vocal_checkpoints/` ou `checkpoints/`
2. Charger le dataset MUSDB depuis `MUSDB18/musdb18/`
3. √âvaluer tous les tracks du test set
4. Sauvegarder les r√©sultats dans `./eval/`

### Options avanc√©es

```bash
# Sp√©cifier un checkpoint particulier
python evaluate.py --checkpoint vocal_checkpoints/best_model.pth

# √âvaluer seulement les 5 premiers tracks (pour tester rapidement)
python evaluate.py --n-tracks 5

# Sp√©cifier un chemin diff√©rent pour MUSDB
python evaluate.py --musdb-path /chemin/vers/musdb18

# Forcer l'utilisation du CPU
python evaluate.py --cpu

# Changer le r√©pertoire de sortie
python evaluate.py --output-dir ./my_eval_results

# Sp√©cifier le nombre de canaux du mod√®le (si diff√©rent de 16)
python evaluate.py --n-channels 16
```

### Exemple complet

```bash
python evaluate.py \
    --checkpoint vocal_checkpoints/best_model.pth \
    --musdb-path MUSDB18/musdb18 \
    --n-channels 16 \
    --n-tracks 10 \
    --output-dir ./eval_results
```

## üìä R√©sultats

### Fichiers g√©n√©r√©s

Apr√®s l'√©valuation, vous trouverez dans le r√©pertoire de sortie (`./eval/` par d√©faut) :

1. **`evaluation_results.csv`** : Tableau d√©taill√© avec les scores pour chaque track
   - Colonnes : `track`, `SDR`, `SIR`, `SAR`
   - Format CSV pour analyse ult√©rieure

2. **`summary.txt`** : R√©sum√© textuel avec les moyennes globales
   - Contient les moyennes et √©carts-types pour SDR, SIR, SAR

3. **Fichiers JSON par track** : G√©n√©r√©s automatiquement par `museval`
   - Un fichier par track avec les scores d√©taill√©s
   - Format standard BSSEval v4

### M√©triques expliqu√©es

- **SDR (Signal-to-Distortion Ratio)** : Mesure la qualit√© globale de la s√©paration
  - Plus √©lev√© = meilleur
  - Typiquement entre -5 dB et 15 dB pour la s√©paration vocale

- **SIR (Signal-to-Interference Ratio)** : Mesure la capacit√© √† s√©parer la source cible des autres sources
  - Plus √©lev√© = moins d'interf√©rence des autres instruments
  - Typiquement entre 0 dB et 20 dB

- **SAR (Signal-to-Artifacts Ratio)** : Mesure la qualit√© du signal reconstruit (artefacts introduits)
  - Plus √©lev√© = moins d'artefacts
  - Typiquement entre 0 dB et 15 dB

### Exemple de sortie

```
======================================================================
R√âSULTATS GLOBAUX
======================================================================

Nombre de tracks √©valu√©s : 50

M√©triques moyennes (vocals) :
  SDR : 5.23 ¬± 2.15 dB
  SIR : 8.45 ¬± 3.21 dB
  SAR : 4.12 ¬± 1.89 dB
```

## üîç Interpr√©tation des r√©sultats

### R√©sultats typiques

Pour un mod√®le U-Net bien entra√Æn√© sur MUSDB :
- **SDR** : 4-7 dB (bon), 7-10 dB (tr√®s bon)
- **SIR** : 6-10 dB (bon), 10-15 dB (tr√®s bon)
- **SAR** : 3-6 dB (bon), 6-9 dB (tr√®s bon)

### Comparaison avec l'article

L'article de r√©f√©rence (https://openaccess.city.ac.uk/id/eprint/19289/) peut servir de point de comparaison. Les r√©sultats d√©pendent de :
- La taille du mod√®le
- Le nombre d'epochs d'entra√Ænement
- La quantit√© de donn√©es utilis√©es
- Les hyperparam√®tres (learning rate, batch size, etc.)

## ‚ö†Ô∏è Probl√®mes courants

### Erreur : "No module named 'museval'"

**Solution** :
```bash
pip install museval
```

### Erreur : "Checkpoint not found"

**Solution** : Sp√©cifiez explicitement le chemin :
```bash
python evaluate.py --checkpoint vocal_checkpoints/best_model.pth
```

### Erreur : "MUSDB dataset not found"

**Solution** : V√©rifiez que le dataset est bien t√©l√©charg√© et sp√©cifiez le chemin :
```bash
python evaluate.py --musdb-path /chemin/vers/musdb18
```

### Erreur : "CUDA out of memory"

**Solution** : Utilisez le CPU ou r√©duisez le nombre de tracks :
```bash
python evaluate.py --cpu --n-tracks 5
```

## üìù Pour le rapport

Pour votre rapport de TP, vous pouvez :

1. **Inclure les moyennes globales** : SDR, SIR, SAR avec √©carts-types
2. **Analyser quelques tracks sp√©cifiques** : Montrer les variations entre diff√©rents types de musique
3. **Comparer avec l'article** : Discuter des diff√©rences et similitudes
4. **Visualiser les r√©sultats** : Cr√©er des graphiques √† partir du CSV g√©n√©r√©

### Exemple de code pour analyser les r√©sultats

```python
import pandas as pd
import matplotlib.pyplot as plt

# Charger les r√©sultats
df = pd.read_csv('./eval/evaluation_results.csv')

# Afficher les statistiques
print(df.describe())

# Cr√©er un graphique
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
df.boxplot(column=['SDR', 'SIR', 'SAR'], ax=axes)
plt.tight_layout()
plt.savefig('evaluation_metrics.png')
```

## üéØ Prochaines √©tapes

Apr√®s l'√©valuation :

1. **Analyser les r√©sultats** :** Identifier les points forts et faibles du mod√®le
2. **Am√©liorer le mod√®le** : Ajuster les hyperparam√®tres si n√©cessaire
3. **Tester sur d'autres donn√©es** : √âvaluer la g√©n√©ralisation (bonus du TP)
4. **Pr√©parer le rapport** : Documenter les r√©sultats et les analyses

---

**Bon √©valuation ! üéµ**

